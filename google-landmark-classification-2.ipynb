{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import necessary libraries**","metadata":{}},{"cell_type":"code","source":"import shutil\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\n\n#Seed for making reproducible experiments\nseed = 612","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.image as mpimg","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/landmark-recognition-2020/train.csv\")\ntrain_data.sample(5, random_state=seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Unique labels:', train_data['landmark_id'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Images per label:',train_data.groupby('landmark_id').count().mean() )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_count = (train_data.groupby('landmark_id').count()).sort_values(by ='id',ascending = False).reset_index()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_count['percent_data'] = (landmarks_count.id.cumsum()/1580470)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_count[landmarks_count['percent_data'] > 0.71]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_count[50:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\nplt.scatter(landmarks_count[40:]['landmark_id'],landmarks_count[40:]['id'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,7))\nplt.title(\"Top 20 most frequent landmarkrs\")\nsns.barplot(x='landmark_id', y='id', data=landmarks_count.head(20), palette=\"mako\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,7))\nplt.title(\"Top 20 most frequent landmarkrs\")\nsns.barplot(x='landmark_id', y='id', data=landmarks_count.tail(20), palette=\"mako\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\nplt.scatter(landmarks_count[4000:]['landmark_id'],landmarks_count[4000:]['id'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\nplt.scatter(landmarks_count[5:4000]['landmark_id'],landmarks_count[5:4000]['id'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data subset for model","metadata":{}},{"cell_type":"code","source":"data_subset = pd.read_csv('../input/sampled-data-1000/Samples 1000.csv')\ndata_subset_images = train_data[train_data['landmark_id'].isin(data_subset['landmark_id'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #Check data distribution\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.pyplot import subplots\n\ncolors = np.array(['#4285f4','#34a853','#fbbc05','#ea4335'])\n#Define the order in which to display the graph\norder = ['1-5','5-10','10-50','50-100','100-200','200-500','>=500']\nf, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n\n\ndef plot_distribution(data_f, data_k, axis):\n    x=data_f.landmark_id.value_counts().index\n    y=pd.DataFrame(data_f.landmark_id.value_counts())\n\n    #Create a variable to group the number of image sin each class\n    y.loc[(y['landmark_id']>=500,'Number of images')] = '>=500'\n    y['Number of images'] = np.where((y['landmark_id']>=200) & (y['landmark_id']<500),'200-500',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=100) & (y['landmark_id']<200),'100-200',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=50) & (y['landmark_id']<100),'50-100',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=10) & (y['landmark_id']<50),'10-50',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=5) & (y['landmark_id']<10),'5-10',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=0) & (y['landmark_id']<5),'1-5',y['Number of images'])\n\n    y['Number of images'].value_counts().loc[[x for x in order if any(y['Number of images']==x)]].plot(kind = 'bar',color = colors,width = 0.8, ax=axis)\n    axis.set_xlabel('Number of images',fontsize=15)\n    axis.set_ylabel('Number of classes',fontsize=15)\n    axis.set_title(data_k,fontsize=17)\n    \nplot_distribution(data_subset_images, 'Sample', ax1)\nplot_distribution(train_data, 'Original', ax2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel train_data\ndel landmarks_count\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_subset_images.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"TRAIN_DIR = '../input/landmark-recognition-2020/train/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data_subset_images['id'], data_subset_images['landmark_id'], test_size=0.2, random_state=42, stratify = data_subset_images['landmark_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_subset_images['train'] = 1\ndata_subset_images.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('X_train:',X_train.shape)\nprint('y_train:',y_train.shape)\nprint('X_test:',X_test.shape)\nprint('y_test:',y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_subset_images[data_subset_images['train']==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merging traing df\nTraining_images = pd.DataFrame()\nTraining_images['id'] = X_train\nTraining_images['landmark_id'] = y_train\nTraining_images = Training_images[Training_images['landmark_id'].isin(y_test)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merging test df\nTesting_images = pd.DataFrame()\nTesting_images['id'] = X_test\nTesting_images['landmark_id'] = y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Training_images.to_csv('./Training_images.csv')\nTesting_images.to_csv('./Testing_images.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of labels in test and train\nprint(Training_images['landmark_id'].nunique())\nprint(Testing_images['landmark_id'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training_images = Training_images.drop('Unnamed: 0',axis = 1)\n# Testing_images = Testing_images.drop('Unnamed: 0',axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel X_train\ndel y_train\ndel X_test\ndel y_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2,os\nDEST_PATH = '/kaggle/working/resized_images/training_images/'\nos.mkdir('/kaggle/working/resized_images/')\nos.mkdir('/kaggle/working/resized_images/training_images/')\n# Resizing images\ndef images_resize(images):    \n    for i, id in enumerate(images):\n        if os.path.exists(DEST_PATH + f'{id[0]}.jpg'):\n            continue\n        else:\n\n            image_path = os.path.join(TRAIN_DIR, f'{id[0][0]}/{id[0][1]}/{id[0][2]}/{id[0]}.jpg')\n            image = cv2.imread(image_path)\n            new_image = cv2.resize(image,(224,224))\n            cv2.imwrite(os.path.join(DEST_PATH,f'{id[0]}.jpg'),new_image)\n\nimages_resize(Training_images.values)\nprint('Images resized')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for root, dirs, files in os.walk('./resized_images'):\n#     for file in files:\n#         img = cv2.imread(os.path.join(root,file))\n#         print(img,file)\n#         plt.imshow(img)\n#         break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i = 0\n# for root, dirs, files in os.walk('./resized_images'):\n#     for file in files:\n#         img = cv2.imread(os.path.join(root,file))\n#         print(img,file)\n#         plt.imshow(img)\n#         if i == 10:\n#             break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# f.add_subplot(1,2,1)\n# plt.imshow(cv2.imread('../input/landmark-recognition-2020/train/6/d/4/6d4846da6209b860.jpg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"damaged_images = []\nimage_array = []\nfor root, dirs, files in os.walk('./resized_images/training_images'):\n    \n    for file in files:\n        if root == './resized_images/training_images':\n            img = cv2.imread(os.path.join(root,file))\n            if img is None:\n                damaged_images.append(file)\n            else:\n                image_array.append(img)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(image_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test dataset\nDEST_PATH_1 = '/kaggle/working/resized_images/testing_images/'\nos.mkdir('/kaggle/working/resized_images/testing_images/')\n# Resizing images\ndef images_resize(images):    \n    for i, id in enumerate(images):\n        \n        if os.path.exists(DEST_PATH_1 + f'{id[0]}.jpg'):\n            continue\n        else:\n            image_path = os.path.join(TRAIN_DIR, f'{id[0][0]}/{id[0][1]}/{id[0][2]}/{id[0]}.jpg')\n            image = cv2.imread(image_path)\n            new_image = cv2.resize(image,(224,224))\n            cv2.imwrite(os.path.join(DEST_PATH_1,f'{id[0]}.jpg'),new_image)\n\nimages_resize(Testing_images.values)\nprint('Images resized')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cv2.imread('/kaggle/working/resized_images/testing_images/0d7d04144065ad08.jpg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEST_PATH_1 = '/kaggle/working/resized_images/testing_images/'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"damaged_images_test = []\nimage_array_test = []\nfor root, dirs, files in os.walk('./resized_images/testing_images'):\n    \n    for file in files:\n        if root == './resized_images/testing_images':\n            img = cv2.imread(os.path.join(root,file))\n            if img is None:\n                damaged_images_test.append(file)\n            else:\n                image_array_test.append(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(image_array_test))\nlen(damaged_images_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.optimizers import Adam\nfrom keras.applications import ResNet152\nfrom keras.applications import ResNet101\nimport os,cv2\nimport matplotlib.pyplot as plt \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_model = ResNet50(weights='imagenet', include_top = False, input_shape = (224,224,3))\n\nfor layer in res_model.layers[:143]:\n    layer.trainable = False\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Flatten, BatchNormalization, Dropout, Dense, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n    \ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom sklearn.metrics import log_loss, roc_auc_score, accuracy_score\nfrom keras.losses import categorical_crossentropy\nfrom keras.metrics import categorical_accuracy\nfrom keras import backend as K\nfrom keras.callbacks import *\nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.CategoricalAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n      \"acc\", f1_m\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(res_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(1024,activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(943,activation = 'softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Training_images['id_new'] = Training_images['id'].astype(str) + '.jpg' \nTraining_images['id_new']\nTesting_images['id_new'] = Testing_images['id'].astype(str) + '.jpg' \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Testing_images['landmark_id_new'] = Testing_images['landmark_id'].astype(str)\nTraining_images['landmark_id_new'] = Training_images['landmark_id'].astype(str)\nTesting_images['id_new'] = Testing_images['id_new'].astype(str)\nTraining_images['id_new'] = Training_images['id_new'].astype(str)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 64\ntrain_datagen = ImageDataGenerator()\n                                  \n    \nval_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow_from_dataframe(dataframe = Training_images,\n                                                       directory = './resized_images/training_images/',\n                                                       x_col = 'id_new',\n                                                       y_col = 'landmark_id_new',\n                                                    class_mode=\"categorical\",\n                                                    preprocessing_function = preprocess_input\n#                                                    ,batch_size = batch_size\n                                                   )\nval_generator = val_datagen.flow_from_dataframe(dataframe = Testing_images,\n                                                       directory = './resized_images/testing_images/',\n                                                       x_col = 'id_new',\n                                                       y_col = 'landmark_id_new',\n                                                class_mode=\"categorical\",\n                                                preprocessing_function = preprocess_input\n                                               )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_base = model.fit(\n        train_generator,\n#         steps_per_epoch=50,\n        epochs=epochs,\n        validation_data=val_generator)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history_base.history['tp'])\nprint(history_base.history['tn'])\nprint(history_base.history['fp'])\nprint(history_base.history['fn'])\n\n# Class accuracy\ntotal = np.array(history_base.history['tp'])+np.array(history_base.history['tn'])+np.array(history_base.history['fp'])+np.array(history_base.history['fn'])\n\nactual = np.array(history_base.history['tp'])+np.array(history_base.history['tn'])\n\naccuracy = actual/total\n\naccuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nY_pred = model.predict(val_generator, 3710 // 64+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(val_generator.classes, y_pred))\n\nConfusionMat = confusion_matrix(val_generator.classes, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nConfusionMat_1 = (ConfusionMat.astype('float') / ConfusionMat.sum(axis=1)[:, np.newaxis])\n\nClassAccuracy = sorted(ConfusionMat_1.diagonal(),reverse = True)\nClassAccuracy[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model 3**","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/classification_models.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for keras\nfrom classification_models.keras import Classifiers\n\n# for tensorflow keras\nfrom classification_models.tfkeras import Classifiers\n\nClassifiers.models_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SeResNeXT101, preprocess_input = Classifiers.get('seresnext101')\nmodel_SeResNeXT101 = SeResNeXT101(include_top = False, input_shape=(224, 224, 3), weights='imagenet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNet101v2, preprocess_input = Classifiers.get('resnet101v2')\nmodel_ResNet101v2 = ResNet101v2(include_top = False, input_shape=(224, 224, 3), weights='imagenet')\n\nResNet152, preprocess_input = Classifiers.get('resnet152')\nmodel_ResNet152 = ResNet152(include_top = False, input_shape=(224, 224, 3), weights='imagenet')\n!pip install efficientnet\nimport efficientnet.keras as efn \nmodel_EfficientNetB3 = efn.EfficientNetB3(weights='imagenet') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model_SeResNeXT101.layers[:2670]:\n    layer.trainable = False\n    \n    \nfor layer in model_ResNet152.layers[:523]:\n    layer.trainable = False\n\n    \nfor layer in model_ResNet101v2.layers[:302]:\n    layer.trainable = False\n\n    \nfor layer in model_EfficientNetB3.layers[:307]:\n    layer.trainable = False\n\n\n# for i, layer in enumerate(model_EfficientNetB3.layers):\n#     print(i, layer.name,'-',layer.trainable)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1 = Sequential()\nmodel_1.add(model_SeResNeXT101)\nmodel_1.add(GlobalAveragePooling2D())\nmodel_1.add(Flatten())\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dense(1024,activation = 'relu'))\nmodel_1.add(Dropout(0.5))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dense(512,activation = 'relu'))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dense(943,activation = 'softmax'))\n\nmodel_1.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2 = Sequential()\nmodel_2.add(model_ResNet152)\nmodel_2.add(GlobalAveragePooling2D())\nmodel_2.add(Flatten())\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(1024,activation = 'relu'))\nmodel_2.add(Dropout(0.5))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(512,activation = 'relu'))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(943,activation = 'softmax'))\n\nmodel_2.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_3 = Sequential()\nmodel_3.add(model_ResNet101v2)\nmodel_3.add(GlobalAveragePooling2D())\nmodel_3.add(Flatten())\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(1024,activation = 'relu'))\nmodel_3.add(Dropout(0.5))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(512,activation = 'relu'))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(943,activation = 'softmax'))\n\nmodel_3.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_4 = Sequential()\nmodel_4.add(model_EfficientNetB3)\n# model_4.add(GlobalAveragePooling2D())\nmodel_4.add(Flatten())\nmodel_4.add(BatchNormalization())\nmodel_4.add(Dense(1024,activation = 'relu'))\nmodel_4.add(Dropout(0.5))\nmodel_4.add(BatchNormalization())\nmodel_4.add(Dense(512,activation = 'relu'))\nmodel_4.add(BatchNormalization())\nmodel_4.add(Dense(943,activation = 'softmax'))\n\nmodel_4.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 64\ntrain_datagen = ImageDataGenerator()\n                                  \n    \nval_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow_from_dataframe(dataframe = Training_images,\n                                                       directory = './resized_images/training_images/',\n                                                       x_col = 'id_new',\n                                                       y_col = 'landmark_id_new',\n                                                    class_mode=\"categorical\",\n                                                    preprocessing_function = preprocess_input\n#                                                    ,batch_size = batch_size\n                                                   )\nval_generator = val_datagen.flow_from_dataframe(dataframe = Testing_images,\n                                                       directory = './resized_images/testing_images/',\n                                                       x_col = 'id_new',\n                                                       y_col = 'landmark_id_new',\n                                                class_mode=\"categorical\",\n                                                preprocessing_function = preprocess_input\n\n#                                     ,batch_size= batch_size\n                                               )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_1 = model_1.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator)\n   \nmodel_1.save('model_1_SEResNeXt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_2 = model_2.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator) \n\nmodel_2.save('model_2_ResNet152')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_3 = model_3.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator)\n\nmodel_3.save('model_3_ResNet101v2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_4 = model_4.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator)\n\nmodel_4.save('model_EfficientNetB3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}